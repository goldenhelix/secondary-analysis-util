name: Compress and Index Genomic Files
description: Compress, index, and validate genomic files (VCF, BAM, CRAM, BED, etc.)
auto_generate_session_for_account: "{workspaceBot}"

agent_requirements:
  cpu_cores: 4
  memory_gb: 8

parameters:
  - name: input_directory
    type: directory
    label: Input Directory
    help: Directory containing genomic files to compress and index
    supports_location_mode: 'no_append'
    
  - name: compress_vcf
    type: boolean
    label: Compress and index VCFs
    value: "true"
    help: Choose whether to compress and index VCFs
    
  - name: compress_bam
    type: boolean
    label: Index BAMs
    value: "true"
    help: Choose whether to index BAMs
    
  - name: compress_cram
    type: boolean
    label: Index CRAMs
    value: "true"
    help: Choose whether to index CRAMs
    
  - name: compress_bed
    type: boolean
    label: Compress BEDs
    value: "true"
    help: Choose whether to compress BEDs

  - name: compress_fastq
    type: boolean
    label: Compress FASTQs
    value: "true"
    help: Choose whether to compress FASTQs

  - name: unzip_archives
    type: boolean
    label: Unzip ZIP Archives
    value: "true"
    help: Choose whether to unzip ZIP archives

  - name: convert_alignment_files
    type: enum
    label: Convert Alignment Files
    value: "No"
    choices: [No, BAM to CRAM, CRAM to BAM]
    help: Choose whether to convert alignment files to CRAM or BAM. If no, the program will only index the files.
    group: Advanced Options

  - name: remove_uncompressed
    type: boolean
    label: Remove Uncompressed Files
    value: "true"
    help: Choose whether to remove uncompressed files after compression and indexing
    group: Advanced Options

  - name: index_files
    type: boolean
    label: Index Files
    value: "true"
    help: Choose whether to index files after compression
    group: Advanced Options

  - name: skip_out_of_order_vcf
    type: boolean
    label: Skip Out of Order VCFs
    value: "true"
    help: Choose whether to skip VCFs that are out of order. If false, the program will exit with an error if a VCF is out of order.
    group: Advanced Options

  - name: search_subdirectories
    type: boolean
    label: Search Subdirectories
    value: "true"
    help: Choose whether to search subdirectories for genomic files
    group: Advanced Options

  - name: search_pattern
    type: string
    label: Search Pattern
    value: ""
    help: Pattern to search for genomic files (e.g., sample_name*). Only used if non-empty.
    optional: true
    group: Advanced Options

  - name: reference_fasta
    type: file
    label: Reference FASTA
    help: Reference FASTA file. Only used if converting BAM to CRAM or vice versa. If not provided, the default reference will be used.
    supports_location_mode: 'read_only'
    optional: true
    group: Advanced Options

steps:
  - name: compress_and_index
    description: Compress and index genomic files
    type: cmd
    docker:
      image: registry.goldenhelix.com/public/sentieon:202503
    args:
      - |-
        set -euox pipefail

        # Set up scratch space
        cd /scratch

        # Function to compress and index a file
        compress_and_index_vcf() {
        
          # Collect inputs to function
          local file=$1
          local index=$2
          local remove_uncompressed=$3
          local input_directory=$4
          local file_type=${file##*.}  # Get file extension, used to clean up file name

          # Copy file to scratch space (since we support no-append)
          ln -s "$file" .
          local file_name=$(basename "$file")

          # Check if file is already compressed
          # Case 1: File is uncompressed
          # Also check for existing .gz file with the same name
          # Case 2: File is compressed with bgzip
          # Case 3: File is compressed with something else

          # Check if file is already compressed with bgzip
          if tabix -f "$file_name" > /dev/null 2>&1; then  # File is compressed with bgzip
            echo "File $file_name is already compressed with bgzip"
            rm "${file_name}.tbi"
            if [[ "$file_type" != "gz" ]]; then
              mv "$file" "${file}.gz"
              rm "$file_name"
              ln -s "${file}.gz" .
              file_name="${file_name}.gz"
            fi
          elif [[ -f "${input_directory}/${file_name}.gz" && "$file_type" == "vcf" ]]; then
            echo "Found compressed VCF in input directory with same name, skipping..."
            return 1
          elif gzip -t "$file_name" > /dev/null 2>&1; then  # File is compressed with gzip
            echo "File $file_name is compressed with gzip; decompressing and recompressing with bgzip..."
            # Decompress with gunzip and recompress with bgzip
            rm "$file_name"
            cp "$file" .
            file_name=$(basename "$file")
            if [[ "$file_type" != "gz" ]]; then
              mv "$file_name" "${file_name}.gz"
              file_name="${file_name}.gz"
            fi
            gunzip "$file_name"
            bgzip "${file_name%.gz}"
            rm "$file"
            cp "$file_name" "$(dirname "$file")"
          else  # File is not compressed 
            echo "File $file_name is not compressed; compressing..."
            if [[ "$file_type" == "gz" ]]; then
              mv "$file_name" "${file_name%.gz}"
              file_name="${file_name%.gz}"
            fi
            bgzip -c "$file_name" > "$file_name.gz" || { echo "Failed to compress file $file_name, skipping..."; return 1; }
            # Remove uncompressed file if requested
            if [[ "$remove_uncompressed" == "true" ]]; then
              echo "Removing uncompressed file $file"
              rm "$file"
            fi
            file_name="${file_name}.gz"
            cp "$file_name" "$(dirname "$file")"
          fi

          # Index file
          if [[ "$index" == "true" ]]; then
            echo "Indexing file $file_name"
            tabix -p vcf "$file_name" || { echo "Failed to index file $file_name (file may be out of order)"; if [[ "$skip_out_of_order_vcf" == "true" ]]; then echo "Skipping file $file_name and continuing..."; return 1; else echo "Exiting..."; exit 1; fi; }
          fi

          if [[ "$index" == "true" ]]; then
            cp "${file_name}.tbi" "$(dirname "$file")"
          fi

        }

        # Determine whether to search subdirectories or not
        if [[ "$search_subdirectories" == "true" ]]; then
          search_subdirectories=""
        else
          search_subdirectories="-maxdepth 1"
        fi

        # Unzip ZIP archives
        if [[ "$unzip_archives" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*zip" ${search_subdirectories} | \
          while read -r file; do
            echo "Unzipping ZIP archive: $file"
            unzip "$file" -d "$(dirname "$file")"
          done
        fi


        # Search for VCFs
        if [[ "$compress_vcf" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*vcf" -o -name "${search_pattern}*vcf.gz" ${search_subdirectories} | \
          while read -r file; do
            echo "Compressing and indexing VCF: $file"
            compress_and_index_vcf "$file" "$index_files" "$remove_uncompressed" "$input_directory" || { echo "Failed to compress and index VCF: $file, skipping..."; }
          done
        fi

        # Search for and compress FASTQs (FASTQs don't need to be indexed and can be compressed in place)
        if [[ "$compress_fastq" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*fastq" -o -name "${search_pattern}*fq" ${search_subdirectories} | \
          while read -r file; do
            echo "Compressing and indexing FASTQ: $file"
            ln -s "$file" .
            bgzip "${file##*/}"
            cp "${file##*/}.gz" "$(dirname "$file")"
            if [[ "$remove_uncompressed" == "true" ]]; then
              rm "$file"
            fi
          done
        fi

        # Search for BEDs
        if [[ "$compress_bed" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*bed" ${search_subdirectories} | \
          while read -r file; do
            echo "Compressing and indexing BED: $file"
            ln -s "$file" .
            bgzip "${file##*/}"
            cp "${file##*/}.gz" "$(dirname "$file")"
            if [[ "$remove_uncompressed" == "true" ]]; then
              rm "$file"
            fi
          done
        fi

        # Determine whether to convert alignment files to CRAM or BAM
        convert_bam=false
        convert_cram=false  
        if [[ "$convert_alignment_files" == "BAM to CRAM" ]]; then
          convert_bam=true
        elif [[ "$convert_alignment_files" == "CRAM to BAM" ]]; then
          convert_cram=true  
        fi

        # TODO: Update with ENV variable preference for reference FASTA

        # Copy reference FASTA to scratch space if converting BAM to CRAM or vice versa
        if [[ "$convert_bam" == "true" || "$convert_cram" == "true" ]]; then
          # Use default reference if not provided
          if [ -z "$reference_fasta" ]; then
            echo "No reference FASTA file provided, using default reference..."
            reference_fasta="$WORKSPACE_DIR/${RESOURCES_PATH}/${REFERENCE_PATH}"
            if [ ! -f "$reference_fasta" ]; then
              echo "The default reference file does not exist at $reference_fasta"
              echo "Please run the task Download Genomic Reference in the Sentieon Short Reads repository to download the reference and then re-run this task"
              exit 1
            fi
          fi
          cp "$reference_fasta" .
          cp "${reference_fasta}.fai" .
          reference_fasta_name=$(basename "$reference_fasta")
        fi
        
        # Search for BAMs
        if [[ "$compress_bam" == "true" && "$index_files" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*bam" ${search_subdirectories} | \
          while read -r file; do
            ln -s "$file" .
            if [[ "$convert_bam" == "true" ]]; then
              echo "Converting BAM to CRAM: $file"
              samtools view -T "${reference_fasta_name}" -C -o "$(basename "$file" .bam).cram" "$file"
              samtools index "$(basename "$file" .bam).cram"
              cp "$(basename "$file" .bam).cram" "$(dirname "$file")"
              cp "$(basename "$file" .bam).cram.crai" "$(dirname "$file")"
              rm "$file"
              rm "$(basename "$file" .bam).cram"    
            else 
              echo "Indexing BAM: $file"
              samtools index "${file##*/}"
              cp "${file##*/}.bai" "$(dirname "$file")"
            fi
          done
        fi

        # Search for CRAMs
        if [[ "$compress_cram" == "true" && "$index_files" == "true" ]]; then
          find "$input_directory" -type f -name "${search_pattern}*cram" ${search_subdirectories} | \
          while read -r file; do
            ln -s "$file" .
            if [[ "$convert_cram" == "true" ]]; then
              echo "Converting CRAM to BAM: $file"
              samtools view -T "${reference_fasta_name}" -b -o "$(basename "$file" .cram).bam" "$file"
              samtools index "$(basename "$file" .cram).bam"
              cp "$(basename "$file" .cram).bam" "$(dirname "$file")"
              cp "$(basename "$file" .cram).bam.bai" "$(dirname "$file")"
              rm "$file"
              rm "$(basename "$file" .cram).bam"
            else
              echo "Indexing CRAM: $file"
              samtools index "${file##*/}"
              cp "${file##*/}.crai" "$(dirname "$file")"
            fi
          done
        fi
        
        